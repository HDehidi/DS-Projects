{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fded5f",
   "metadata": {},
   "source": [
    "# Homework 02: Naïve Bayes’ Classifier\n",
    "## Hamza Dehidi KU 0077989\n",
    "### October 24, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68708d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21891456",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02615f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "images = np.genfromtxt(r'C:\\Users\\Hamza\\Desktop\\Koç\\2- DASC 521\\4- Assignments\\02-Naïve Bayes’ Classifier\\Initial\\hw02_images.csv', delimiter = \",\")\n",
    "labels = np.genfromtxt(r'C:\\Users\\Hamza\\Desktop\\Koç\\2- DASC 521\\4- Assignments\\02-Naïve Bayes’ Classifier\\Initial\\hw02_labels.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef58bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test\n",
    "images_train = images[:30000,:].astype(int)\n",
    "images_test = images[30000:35001,:].astype(int)\n",
    "\n",
    "y_truth_train = labels[:30000].astype(int)\n",
    "y_truth_test = labels[30000:35001].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a19d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions\n",
    "d = images_train.shape[1]\n",
    "# number of labels\n",
    "k = np.max(y_truth_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfd8d9",
   "metadata": {},
   "source": [
    "## Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c3ad1",
   "metadata": {},
   "source": [
    "### Calculate sample means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a8da7",
   "metadata": {},
   "source": [
    "$\\widehat{\\mu_{c}} = \\dfrac{\\sum\\limits_{i = 1}^{N} x_{i} \\mathbb{1}(y_{i} = c)}{\\sum\\limits_{i = 1}^{N} \\mathbb{1}(y_{i} = c)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample means for each dataset along each dimension\n",
    "\n",
    "sample_means = np.reshape([np.mean((images_train[y_truth_train == (c + 1)]),axis=0)\n",
    "                           for c in range(k)],(k,d))\n",
    "                           \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98767419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254.99866667 254.98416667 254.85616667 ... 254.679      254.87816667\n",
      "  254.95933333]\n",
      " [254.99733333 254.99733333 254.9965     ... 254.96883333 254.99216667\n",
      "  254.98866667]\n",
      " [254.99933333 254.99933333 254.99233333 ... 251.52483333 254.4725\n",
      "  254.97483333]\n",
      " [254.99666667 254.98983333 254.91416667 ... 252.39516667 254.44166667\n",
      "  254.93666667]\n",
      " [254.999      254.98433333 254.93783333 ... 250.673      253.23333333\n",
      "  254.79083333]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95ae62",
   "metadata": {},
   "source": [
    "### Calculate sample standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ccafc",
   "metadata": {},
   "source": [
    "$\\widehat{\\sigma_{c}} = \\dfrac{\\sum\\limits_{i = 1}^{N} \\sqrt{(x_{i} - \\widehat{\\mu_{c}})^{2}} \\mathbb{1}(y_{i} = c)} {\\sum\\limits_{i = 1}^{N} \\mathbb{1}(y_{i} = c)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d5859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the standard deviation along the specified dimension for specific label.\n",
    "sample_std = np.reshape([(np.std(images_train[y_truth_train == (c + 1)], axis=0))\n",
    "                                        for c in range(k)],(k,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659546c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03e8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09127736  0.25609108  1.31090756 ...  5.29826629  3.9117332\n",
      "   1.93959091]\n",
      " [ 0.2065419   0.2065419   0.2163818  ...  1.04076669  0.47057267\n",
      "   0.70062226]\n",
      " [ 0.05163547  0.04081939  0.16002465 ... 18.43665868  6.7881694\n",
      "   1.1061344 ]\n",
      " [ 0.18436076  0.21617116  1.81046936 ... 15.67799977  6.34549162\n",
      "   1.79971911]\n",
      " [ 0.04471018  0.64582342  3.03248555 ... 23.62576428 13.9167006\n",
      "   4.4727787 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52feccf",
   "metadata": {},
   "source": [
    "### Calculate prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb1680",
   "metadata": {},
   "source": [
    "$\\widehat{P}(y_{i} = c) = \\dfrac{\\sum\\limits_{i = 1}^{N} \\mathbb{1}(y_{i} = c)}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc07f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prior probabilities\n",
    "class_priors = [np.mean(y_truth_train == (c + 1)) for c in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02109d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.2, 0.2, 0.2, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(class_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34d115",
   "metadata": {},
   "source": [
    "## Parametric Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90def1b5",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "g_{c}(x) &= \\log p(x | y = c) + \\log P(y = c)\\\\\n",
    "&= -\\dfrac{d}{2} \\log(2 \\pi) - \\sum_{n=1}^{d}(\\log\\sigma_{c})-\\dfrac{1}{2}(x - \\mu_{c})^{T}\\sigma_{c}^{-2}(x - \\mu_{c}) + \\log P(y = c)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62c6b9",
   "metadata": {},
   "source": [
    "## Creating score function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1934938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm using the first method not the Ws.\n",
    "# for i in range(images_test.shape[0]) produces 30,000 itirations,the number of observations in the test_data. \n",
    "# for c in range(k) gives 5 itirations, the number of classes.\n",
    "# remove -.5 with **2 from the second term.\n",
    "\n",
    "def score_func(data_test):\n",
    "    total_scores = np.zeros((data_test.shape[0], 0))\n",
    "    for c in range(k):\n",
    "        scores = np.vstack([- 0.5 * d * np.log(2 * math.pi) - np.sum(np.log(sample_std[c]))\n",
    "                         - 0.5 * np.inner(((data_test[j] - sample_means[c]).T * (sample_std[c]**-2)),(data_test[j] - sample_means[c])) \n",
    "                         + np.log(class_priors[c]) for j in range(data_test.shape[0])])\n",
    "        print(scores.shape)\n",
    "        total_scores = np.hstack((total_scores,scores))\n",
    "        \n",
    "    return total_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adca55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop will assign the highest score for observation.\n",
    "\n",
    "def classifier(data_test):\n",
    "    \n",
    "    scores = score_func(data_test)\n",
    "    print(scores.shape)\n",
    "    y_predicted = np.zeros((data_test.shape[0])).astype(int)\n",
    "    for r in range(data_test.shape[0]):\n",
    "            if scores[r,0] == np.max(scores[r,:]): y_predicted[r] = 1\n",
    "            elif scores[r,1] == np.max(scores[r,:]): y_predicted[r] = 2\n",
    "            elif scores[r,2] == np.max(scores[r,:]): y_predicted[r] = 3\n",
    "            elif scores[r,3] == np.max(scores[r,:]): y_predicted[r] = 4        \n",
    "            elif scores[r,4] == np.max(scores[r,:]): y_predicted[r] = 5            \n",
    "    \n",
    "         \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6813c14",
   "metadata": {},
   "source": [
    "## Calculate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32545d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1)\n",
      "(30000, 1)\n",
      "(30000, 1)\n",
      "(30000, 1)\n",
      "(30000, 1)\n",
      "(30000, 5)\n"
     ]
    }
   ],
   "source": [
    "class_predicted_training = classifier(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8296c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047501af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix for the data points in training set\n",
    "confusion_matrix = pd.crosstab(class_predicted_training, y_truth_train, rownames = ['y_pred'], colnames = ['y_truth'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19eb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predicted_test = classifier(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d22444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix for the data points in test set\n",
    "confusion_matrix = pd.crosstab(class_predicted_test, y_truth_test, rownames = ['y_pred'], colnames = ['y_truth'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f0a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
