{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a Python module for data analysis and manipulation, particularly for *tabular data* and *time-series*. Pandas makes it easy to read and write data in various formats (csv, JSON, SQL, excel etc.), allows for manipulation operations such as merging, reshaping, selecting and helps with data cleaning, and data wrangling. \n",
    "\n",
    "Numpy provides high-performance operations on low-level data structures. Towards this end, each numpy array holds only one type of data (this data can be complex, it doesn't have to be just a number). Keeping one type of data makes many operations faster, but it's restrictive given that we collect data from many sources with different types. Our \"dictionary of numpy arrays\" was a poor-man's solution to this problem.\n",
    "\n",
    "Pandas solves this with `Series` (1-dimensional labeled array) and `DataFrame` (2-dimensional, each colum is labeled and can hold different types of data, each row can be labeled as well, e.g., for temporal indexing) data structures.\n",
    "\n",
    "(Small Note: Not all data is tabular!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas Series**\n",
    "\n",
    "This data structure is built on top of 1-dimensional numpy arrays. The most obvious addition is that each entry has a name (label or `Index` in pandas terminology). Can be initialized similar to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From lists\n",
    "data = pd.Series([0.1,0.3,-0.1,1])\n",
    "print(data)\n",
    "print()\n",
    "print(data[2])\n",
    "print()\n",
    "print(data[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `values` field to reach the underlying numpy array and ``index`` field to reach the *labels* of the data stored as Pandas `Index`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Underlying array\n",
    "print(type(data.values))\n",
    "print(data.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels of the data. Since we did not specify anything, it uses its default RangeIndex\n",
    "print(type(data.index))\n",
    "print(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, index is a `RangeIndex` object. It is also possible to explicitly define labels and access them using these labels (What data structure does this resemble?). Index type also changes according to the data type used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.1,0.3,-0.1,1], index = ['a','b','c','d'])\n",
    "\n",
    "print(type(data.index))\n",
    "print(data.index)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access with the given labels\n",
    "print(data['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer indexing still works but be careful ...\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing with the given index is possible. \n",
    "# This assumes the given order\n",
    "# Important Note: The last index is included!!!!\n",
    "print(data['b':'d'])\n",
    "print()\n",
    "print(data['d':'b':-1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.Series([0.1,0.3,-0.1,1], index = ['d','c','b','a'])\n",
    "print(data2['b':'d']) \n",
    "print()\n",
    "print(data2['b':'d':-1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can give our own integer labels as well\n",
    "data = pd.Series([0.1,0.3,-0.1,1], index = [1,3,6,10])\n",
    "print(type(data.index))\n",
    "print(data.index)\n",
    "print()\n",
    "print(data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the given indices are integers, the below no longer works!\n",
    "# print(data[0]) # uncommenting will give an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can give our own integer labels as well\n",
    "data = pd.Series([0.1,0.3,-0.1,1], index = [1.,3.,6.,10.])\n",
    "print(type(data.index))\n",
    "print(data.index)\n",
    "print()\n",
    "print(data[6.])\n",
    "print(data[6])\n",
    "# print(data[0]) # uncommenting will given an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can mix and match\n",
    "data = pd.Series([0.1,0.3,-0.1,1,5,4,3], index = ['a','b','c','d',1,2,5])\n",
    "\n",
    "print(type(data.index))\n",
    "print(data.index)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid potential ambiguity, the Series data structure has the `loc` and `iloc` fields; `loc` (location) provides access based on given labels and, `iloc` (integer location) provides access based on integer indexing (Python style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.1,0.3,-0.1,1], index = [1,3,6,10])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.1,0.3,-0.1,1], index = ['a','b','c','d'])\n",
    "print(data)\n",
    "print(data.loc['a':'b']) \n",
    "print(data.iloc[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ability to give custom indices makes the Series data structure resemble Python dictionaries. It is not surprising for us to be able to directly initialize a Series data structure with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plate_dict = {'istanbul':'34', 'ankara':'06', 'kocaeli':'41', 'izmir':'35'}\n",
    "\n",
    "plates = pd.Series(plate_dict)\n",
    "\n",
    "print(plates.index)\n",
    "print()\n",
    "print(plates.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plates['istanbul'])\n",
    "print()\n",
    "print(plates['istanbul':'ankara'])\n",
    "print()\n",
    "print(plates.loc['istanbul':'ankara'])\n",
    "print()\n",
    "print(plates.iloc[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick a subset of the keys from the Dictionary as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plates_small = pd.Series(plate_dict, index = ['istanbul', 'ankara'])\n",
    "print(plates_small.index)\n",
    "print(plates_small.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove a data point from a Series using its label with the `drop` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates_missing = plates.drop('izmir') #inplace=True drops it from the original but returns None\n",
    "print(plates.index)\n",
    "print(plates_missing.index)\n",
    "print(plates_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also has the `keys()` method (equivalent to `index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plates.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple `foreach` options for the Series data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for plate in plates:\n",
    "    print(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs dictionaries which return keys \n",
    "for something in plate_dict:\n",
    "    print(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in plates.keys():\n",
    "    print(city)\n",
    "    \n",
    "print()\n",
    "\n",
    "for city in plates.index:\n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuples in plates.items():\n",
    "    print(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city,plate in plates.items():\n",
    "    print(city,plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change gears and see NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several NaN related functions in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fillna(np.mean(a)) #write over NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.fillna(np.mean(a), inplace = True)\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(a) # Check whether values are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can replace values as well (specifying what to replace can get relatively complex if you want to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace([6,8],12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "a.replace([6,8],12, inplace=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.values<5)\n",
    "print(type(a.values<5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a<5)\n",
    "print(type(a<5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace(a.values[a.values<5],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace(np.nan,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply arbitrary functions on each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Custom function\n",
    "def dummy(x):\n",
    "    if x < 5:\n",
    "        return 5\n",
    "    else:\n",
    "        return x\n",
    "a.apply(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy(a) # this will give an error since all the statements inside dummy are designed for single values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas Data Frame**\n",
    "\n",
    "`DataFrame` data structure can be thought of as a 2D numpy array with indexed rows and columns, where each column can hold different data types. It consists of `Series` data structures with the same indices (but different data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_count_dict = {'istanbul': 4187531, 'ankara':2003921, 'kocaeli':393605, 'izmir':1400809}\n",
    "\n",
    "vehicle_count = pd.Series(vehicle_count_dict)\n",
    "\n",
    "road = pd.DataFrame({'plate':plates,'vehicle count':vehicle_count})\n",
    "print(road)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the following properties: ``values`` (2-dim numpy array), ``index`` (pd.Index, row names) and additionally ``columns`` (pd.Index, column names, equivalent version ``keys()``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(road.values))\n",
    "print(road.values)\n",
    "print(road.values.dtype) #object, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(road.index))\n",
    "print(road.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(road.columns))\n",
    "print(road.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(road.keys()))\n",
    "print(road.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary type access to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(road['plate'])\n",
    "print()\n",
    "print(road['vehicle count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be directly created from 2-dim numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(3, 2)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "data = pd.DataFrame(x,\n",
    "             columns=['abc', 'qwe'],\n",
    "             index=['a', 'b', 'c'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.to_numpy().dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main strengths of Pandas is to load files into dataframes Let's start with a simple `read_csv` function call and load the student_grades.csv from matplotlib exercise. The file looks like this:\n",
    "\n",
    "`Letter,Total,Exams,HWs`  \n",
    "`D,42.50,28.18,14.32`  \n",
    "`F,33.21,18.75,14.46`  \n",
    "`D+,50.01,30.85,19.16`  \n",
    "`F,10.28,8.78,1.50`  \n",
    "`D+,47.59,32.75,14.84`  \n",
    "`B,75.17,41.45,33.72`  \n",
    "`B,74.82,39.23,33.79`  \n",
    "`...` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df = pd.read_csv('student_grades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice:\n",
    "* Notebook displays the first and last 5 entries by default\n",
    "* The column names/labels are *inferred* \n",
    "* The row labels aka indices are integers\n",
    "\n",
    "Let's Shift+Tab the signature! \n",
    "\n",
    "We will see more of this but let's continue with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print output\n",
    "print(student_grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side Note:\n",
    "from IPython.display import display\n",
    "display(student_grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column and row labels:\n",
    "print(student_grades_df.columns)\n",
    "print(student_grades_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at desired number of points from the *head* and the *tail*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10\n",
    "student_grades_df.head(10) #if no integer is given, only 5 of them are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 7\n",
    "student_grades_df.tail(7) #if no integer is given, only 5 of them are displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` data structure provides a method called `describe` to show a few simple descriptive statistics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where did the letter grades go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over **access** with `loc` and `iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc`: integer location access (supports all the Pythonic stuff!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row, col] \n",
    "print(student_grades_df.iloc[0, 1])  # 0th row 1st column is Letter the Total of the first student\n",
    "print(student_grades_df.iloc[1, 0])  # Letter grade of 1st student\n",
    "print(student_grades_df.iloc[93, 2])  # Exam average of 93rd student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row]\n",
    "print(student_grades_df.iloc[3])     # All data for the 3rd student United Kindom için bütün veriler \n",
    "print()\n",
    "\n",
    "# iloc[:, column]\n",
    "print(student_grades_df.iloc[:, 1])  # all total grades (only display first and last 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing\n",
    "print(student_grades_df.iloc[10:15, 0:2])  # students 10,11,12,13,14 and their letter and total grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_grades_df.iloc[1:10:2, ::-1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc`: location access (i.e. access with row and column names/labels/indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row, col] \n",
    "print(student_grades_df.loc[4, 'Letter'])\n",
    "print(student_grades_df.loc[91, 'HWs'])\n",
    "print(student_grades_df.loc[50, 'Exams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row]\n",
    "print(student_grades_df.loc[94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[:, col]\n",
    "print(student_grades_df.loc[:, 'Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing - note the inclusion of the end even with integers!\n",
    "print(student_grades_df.loc[0:10, 'Total':'HWs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column access for `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_grades_df.loc[:, 'Exams'])  # 'Exams' column\n",
    "print()\n",
    "print(student_grades_df['Exams'])        # 'Exams' column\n",
    "print()\n",
    "print(student_grades_df.Exams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "student_grades_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example with named rows (transport.csv):  \n",
    "`country, car, bus, rail`  \n",
    "`some more explanations, yada yada yada`  \n",
    "`France, 86.1, 5.3, 8.6`  \n",
    "`Germany, 85.2, 7.1, 7.7`  \n",
    "`Netherlands, 86.4, 4.6, 9`  \n",
    "`United Kingdom, 88.2, 6.5, 5.3` \n",
    "\n",
    "The second row is just comments. There are spaces after the commas. It looks like the first column may actually be used as column indices. Let's incorporate these into our file reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = pd.read_csv('transport.csv', skiprows=[1], skipinitialspace=True, index_col=0)\n",
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.columns)\n",
    "print(tran.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.loc['France', 'bus'])\n",
    "print(tran.loc['Germany', 'car'])\n",
    "print(tran.loc['Netherlands', 'rail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.loc['France'])\n",
    "print()\n",
    "print(tran.loc['Germany'])\n",
    "print()\n",
    "print(tran.loc['Netherlands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.loc['Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.loc[:, 'car'])  \n",
    "print()\n",
    "print(tran['car'])\n",
    "print()\n",
    "print(tran.car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` objects have their own functions similar to numpy arrays. In addition, `DataFrame` objects can be treated as numpy arrays if their columns have appropriate dtypes. As a result, we can call numpy function on data-frames directly. \n",
    "\n",
    "\n",
    "Let's see a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The most car usage among given countries:', tran['car'].max())\n",
    "print('Country with most car usage:', tran['car'].idxmax()) #idxmax is equilvalnet to argmax \n",
    "print('Average car usage among given countries:', tran['car'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average total grades:', student_grades_df['Total'].mean())\n",
    "print('Median total grades:', student_grades_df['Total'].median())\n",
    "print('Standard deviation of total grades:', student_grades_df['Total'].std())\n",
    "print()\n",
    "# Returns a dataframe since there can be items with the same count\n",
    "print('Most frequent grade:', student_grades_df['Letter'].mode()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_grades_df.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most frequent grade:', student_grades_df['Letter'].mode()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log(student_grades_df) # this will given an error, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = student_grades_df.loc[:,'Total':'HWs']\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log(student_grades_df.loc[:,'Total':'HWs'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(student_grades_df.drop(['Letter'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(student_grades_df['Total']))\n",
    "c = np.log(student_grades_df['Total'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class questions:\n",
    "* apply with more than 1 dimension (use the same function on multiple columns or have a single function take input from multiple columns)?\n",
    "* Non-unique indices\n",
    "* Frequencies of the Letter column -> more generally descriptive statistics of categorical and/or ordinal data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transport_2.csv') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_nu = pd.read_csv('transport_2.csv', index_col = 0, skiprows=[1])\n",
    "tran_nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_nu.loc['Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.index.is_unique)\n",
    "print(tran_nu.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df['Letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df['Letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df['Exams']+student_grades_df['HWs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use conditional indexing with data-frames as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran['car'] > 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.index[tran['car'] > 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Countries that have more than 86% car usage:')\n",
    "print(tran.index[tran['car'] > 86].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.loc[tran.index[tran['car'] > 86]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.loc[tran['car'] > 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it were the other way\n",
    "tmp = tran.T\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc['car'] > 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns[tmp.loc['car'] > 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp[tmp.columns[tmp.loc['car'] > 86]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:** \n",
    "* Display all grades of students with Total > 60\n",
    "* Display only letter grades of students with Total > 60\n",
    "* Display all grades of students with B-,B and B+ students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.loc[student_grades_df['Total'] > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.loc[student_grades_df['Total'] > 60].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df[student_grades_df['Total'] > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df['Letter'].loc[student_grades_df['Total'] > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired = (student_grades_df['Letter'] == 'B') | (student_grades_df['Letter'] == 'B-') | (student_grades_df['Letter'] == 'B+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.loc[desired]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns to `DataFrames` and new items to `Series` objects can be done analogous to adding items to dictionaries with key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran['public_transport'] = tran['bus'] + tran['rail']\n",
    "print('Country with the most public transport:', tran.public_transport.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tran['public_transport']\n",
    "print(type(a))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Austria'] = 14.2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can similarly assign new values\n",
    "a['Germany'] = 15\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original is unchanged\n",
    "tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tranTmp = tran.copy()\n",
    "tranTmp['example1'] = np.log(tran['car']/tran['bus'])**2+2\n",
    "\n",
    "tranTmp['example2'] = np.array([str(tran['car'][0])+'-1','b','c','d'])\n",
    "\n",
    "tranTmp['example3'] = [(1,0),(0,1),(0,0),(1,0)]\n",
    "tranTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranTmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Check if the total of `Exam` and `HWs` columns are really equal to the `Total` columns (for `student_grades_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(student_grades_df['Exams'] + student_grades_df['HWs'] == student_grades_df['Total']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(student_grades_df['Exams'] + student_grades_df['HWs'] - student_grades_df['Total'] < 1e-2).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting with DataFrames**  \n",
    "We can use Matplotlib with Pandas to plot data in dataframe and series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single series\n",
    "plt.plot(tran['bus'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire frame\n",
    "plt.plot(tran)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire frame with a legend\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(tran,linewidth = 2.5)\n",
    "plt.legend(tran.columns, fontsize = 16)\n",
    "plt.tick_params(labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has its own plotting commands as well (uses matplotlib in the background as default but something else can be used if really needed, see backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.plot(figsize = (12,7), fontsize =16)  # all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tran['bus'].plot(kind='bar') #Single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.plot(kind='bar')  # all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.T.plot(kind='bar')  # all columns of the transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.T.plot(kind='barh')  # all columns of the transpose, horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.loc['Germany'].plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't make sense since public transport is the sum of bus and rail\n",
    "tran.loc['Germany','car':'rail'].plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting DataFrames**  \n",
    "\n",
    "DataFrames provide the `.sort_values` method for sorting. This can be done inplace with `inplace=True` or a new one can be created with `inplace=False`. The `by` argument of `sort_values` let's us chose the desired column to be sorted by. We can use the `ascending` argument to set the direction of sorting. We can sort based on row values by setting the `axis` argument to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Car usage from most to least:')\n",
    "display(tran.sort_values(by='car', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bus usage from least to most:')\n",
    "display(tran.sort_values(by='bus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.sort_values(by='bus', inplace=True) # Nothing is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting \n",
    "display(tran.sort_values(by='Germany',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming** columns is possible with the `.rename` method and a dictionary (keys correspond to the current names, values correspond to the desired names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tran)\n",
    "tran.rename(columns={'bus': 'coach', \n",
    "                     'rail': 'train'}, inplace=True)\n",
    "display(tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the name of the index column (`'country'` -> `'somewhere in Europe'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tran.index.names = ['somewhere in Europe']\n",
    "display(tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to file reading (sort of): \n",
    "Write the following in a code cell and press tab: `pd.read` and `tran.to` or alternatively visit [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.to_csv('transport_edited.csv')\n",
    "\n",
    "with open('transport_edited.csv','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.to_json('transport_edited.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index name is lost. There are roundabout ways to keep it\n",
    "tran_json = pd.read_json('transport_edited.json')\n",
    "tran_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades_df.to_json('sg.json') \n",
    "sg_json=pd.read_json('sg.json')\n",
    "sg_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_mi = tran.copy()\n",
    "arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]\n",
    "mi = pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))\n",
    "tran_mi.index=mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_mi.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_mi.loc[(1,'red')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_mi.loc[(2,'red')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_tran = pd.read_csv('transport.csv',index_col=[0,2], skiprows= [1])\n",
    "tmp_tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_tran.loc['France'])\n",
    "print()\n",
    "print(tmp_tran.loc[('France',5.3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Reading the auto-mpg.data together and playing around with it together. Let's look at several columns:\n",
    "\n",
    "``\n",
    "18.0   8   307.0      130.0      3504.      12.0   70  1\t\"chevrolet chevelle malibu\"\n",
    "15.0   8   350.0      165.0      3693.      11.5   70  1\t\"buick skylark 320\"\n",
    "18.0   8   318.0      150.0      3436.      11.0   70  1\t\"plymouth satellite\"\n",
    "16.0   8   304.0      150.0      3433.      12.0   70  1\t\"amc rebel sst\"\n",
    "17.0   8   302.0      140.0      3449.      10.5   70  1\t\"ford torino\"\n",
    "15.0   8   429.0      198.0      4341.      10.0   70  1\t\"ford galaxie 500\"\n",
    "14.0   8   454.0      220.0      4354.       9.0   70  1\t\"chevrolet impala\"\n",
    "...\n",
    "11.0   8   350.0      180.0      3664.      11.0   73  1\t\"oldsmobile omega\"\n",
    "20.0   6   198.0      95.00      3102.      16.5   74  1\t\"plymouth duster\"\n",
    "21.0   6   200.0      ?          2875.      17.0   74  1\t\"ford maverick\"\n",
    "19.0   6   232.0      100.0      2901.      16.0   74  1\t\"amc hornet\"\n",
    "15.0   6   250.0      100.0      3336.      17.0   74  1\t\"chevrolet nova\"\n",
    "31.0   4   79.00      67.00      1950.      19.0   74  3\t\"datsun b210\"\n",
    "26.0   4   122.0      80.00      2451.      16.5   74  1\t\"ford pinto\"\n",
    "32.0   4   71.00      65.00      1836.      21.0   74  3\t\"toyota corolla 1200\"\n",
    "25.0   4   140.0      75.00      2542.      17.0   74  1\t\"chevrolet vega\"\n",
    "16.0   6   250.0      100.0      3781.      17.0   74  1\t\"chevrolet chevelle malibu classic\"\n",
    "...\n",
    "``\n",
    "\n",
    "Things to notice:\n",
    "* No header or column names. We can specify this ourselves\n",
    "* There is a \"?\" to denote missing data\n",
    "* The columns are not separated by commas but by spaces\n",
    "* The last part is separated by tabs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names are not in the data\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin'] \n",
    "\n",
    "dataset_df = pd.read_csv('auto-mpg.data', \n",
    "                          names=column_names, # giving them manually\n",
    "                          na_values = \"?\",  # missing values\n",
    "                          sep=\" \", #spaces\n",
    "                          skipinitialspace=True, #if you do not do this, the parser interprets inbetween spaces as items\n",
    "                          comment='\\t') # Treat the car names as comments to get rid of them, otherwise we need regex\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin is 1:USA, 2:Europe, 3:Japan. Let's add a new column for named origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labelToCountry = {1:'USA',2:'Europe', 3:'Japan'}\n",
    "countryList = [labelToCountry[orig] for orig in dataset_df['Origin']]\n",
    "dataset_df['Origin Names'] = countryList\n",
    "\n",
    "# What else:\n",
    "## replace\n",
    "## apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mapping dictionary\n",
    "#origins = ['USA', 'Europe', 'Japan']\n",
    "#dataset_df['Named Origin'] = [origins[x-1] for x in dataset_df['Origin']]\n",
    "#dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we look at? Some ideas:\n",
    "* Descriptive Statistics\n",
    "* Missing data\n",
    "* Outliers\n",
    "* Number of cylinders vs origin \n",
    "* what else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['Origin Names'].value_counts()/len(dataset_df['Origin Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart by country\n",
    "dataset_df['Origin Names'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['Horsepower'].fillna(dataset_df['Horsepower'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.drop(['Weight'],axis=1).plot(kind='box', figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['Weight'].plot(kind='box', figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot to visually the inspect this hypothesis:\n",
    "# The distribution of the number of cylinders for American cars \n",
    "# tend to have higher values that the same distribution for European and Japanese cars\n",
    "\n",
    "# THIS CELL IS THE BAD VERSION\n",
    "\n",
    "dataset_df[dataset_df['Origin']==1]['Cylinders'].plot(kind='hist')\n",
    "dataset_df[dataset_df['Origin']==2]['Cylinders'].plot(kind='hist')\n",
    "dataset_df[dataset_df['Origin']==3]['Cylinders'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carNumbers = [dataset_df[dataset_df['Origin']==1]['Cylinders'].value_counts(),\n",
    "              dataset_df[dataset_df['Origin']==2]['Cylinders'].value_counts(),\n",
    "              dataset_df[dataset_df['Origin']==3]['Cylinders'].value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat(carNumbers,axis=1).fillna(0)\n",
    "tmp.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carNumbers[0].rename('USA',inplace= True)\n",
    "carNumbers[1].rename('Europe',inplace= True)\n",
    "carNumbers[2].rename('Japan',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCylinders = pd.concat(carNumbers,axis=1).fillna(0)\n",
    "finalCylinders.plot(kind='bar')\n",
    "plt.title('Origin vs Cylinder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation example:  \n",
    "* acceleration and cylinders\n",
    "* acceleration and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by plotting\n",
    "plt.scatter(dataset_df['Cylinders'],dataset_df['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "for i in range(1,4):\n",
    "    f = plt.subplot(1,3,i)\n",
    "    f.scatter(dataset_df[dataset_df['Origin']==i]['Cylinders'],dataset_df[dataset_df['Origin']==i]['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(dataset_df['Cylinders'],dataset_df['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset_df['Model Year'],dataset_df['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "for i in range(1,4):\n",
    "    f = plt.subplot(1,3,i)\n",
    "    f.scatter(dataset_df[dataset_df['Origin']==i]['Model Year'],dataset_df[dataset_df['Origin']==i]['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(dataset_df['Model Year'],dataset_df['Acceleration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationPlots(dataFrame, xname, yname, labelName = None, plotHandle = None):\n",
    "    if plotHandle == None:\n",
    "        plt.figure(figsize=(10,7))\n",
    "        plotHandle = plt\n",
    "    if labelName:\n",
    "        items = dataFrame[labelName].unique()\n",
    "        for i in items:\n",
    "            inds = dataset_df[labelName]==i\n",
    "            plotHandle.scatter(dataset_df[inds][xname],dataset_df[inds][yname])\n",
    "        plt.legend(items)\n",
    "    else:\n",
    "        plotHandle.scatter(dataset_df[xname],dataset_df[yname])\n",
    "    \n",
    "    plt.xlabel(xname)\n",
    "    plt.ylabel(yname)\n",
    "    return np.corrcoef(dataset_df[xname],dataset_df[yname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationPlots(dataset_df,'MPG','Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationPlots(dataset_df,'MPG','Weight','Origin Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationPlots(dataset_df,'Displacement','Cylinders','Model Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelName = 'Origin'\n",
    "\n",
    "if labelName:\n",
    "    dataset= dataset_df.loc[:,dataset_df.dtypes != object].drop(labelName,axis=1)\n",
    "else:\n",
    "    dataset = dataset_df.loc[:,dataset_df.dtypes != object]\n",
    "\n",
    "n = len(dataset.columns)\n",
    "k = 1\n",
    "plt.figure(figsize=(n*3,n*3))\n",
    "for row in dataset.columns:\n",
    "    for col in dataset.columns:\n",
    "        if row == col:\n",
    "            f = plt.subplot(n,n,k)\n",
    "            f.boxplot(dataset_df[row])\n",
    "            k += 1\n",
    "        else:\n",
    "            f = plt.subplot(n,n,k)\n",
    "            k += 1\n",
    "            correlationPlots(dataset_df,row,col,labelName,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.loc[:,dataset_df.dtypes != object].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Time Series Data\n",
    "\n",
    "There is a Python module called [`datetime`](https://docs.python.org/3/library/datetime.html) that provides functionality to manipulate dates and times. Several important classes from this module: \n",
    "* datetime: Dates and time together, same name as the module (month, day, year, hour, second, microsecond).\n",
    "* date: Dates independent of time (month, day, year).\n",
    "* time: Time independent of date (hour, minute, second, microsecond).\n",
    "* timedelta: A duration difference between two date, time, or datetime objects (in microsecond precision)\n",
    "\n",
    "Note: There are some details when dealing with time (timezones, time savings, represantable years, represantable durations, resolution etc.). Instead of going over everything, we will touch upon several points. The module link given above has all these details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#MINYEAR <= year <= MAXYEAR,\n",
    "#1 <= month <= 12,\n",
    "#1 <= day <= number of days in the given month and year,\n",
    "#0 <= hour < 24,\n",
    "#0 <= minute < 60,\n",
    "#0 <= second < 60,\n",
    "#0 <= microsecond < 1000000\n",
    "\n",
    "year = 2022\n",
    "month = 1\n",
    "day = 4\n",
    "hour = 17 \n",
    "minute = 30\n",
    "second  = 15  \n",
    "microsecond = 61283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime(year,month,day))\n",
    "print(datetime.date(year,month,day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime(year,month,day,hour))\n",
    "print(datetime.time(hour))\n",
    "\n",
    "print(datetime.datetime(year,month,day,hour,minute,second,microsecond))\n",
    "print(datetime.time(hour,minute,second,microsecond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDt1 = datetime.datetime(year,month,day,hour,minute,second,microsecond)\n",
    "\n",
    "print(type(fullDt1))\n",
    "print(fullDt1)\n",
    "print(fullDt1.year,fullDt1.month,fullDt1.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2 = 2021\n",
    "month2 = 11\n",
    "day2 = 8\n",
    "hour2 = 12 \n",
    "minute2 = 21\n",
    "second2  = 47  \n",
    "microsecond2 = 8761\n",
    "\n",
    "fullDt2 = datetime.datetime(year2,month2,day2,hour2,minute2,second2,microsecond2)\n",
    "\n",
    "td = fullDt1 - fullDt2\n",
    "print(type(td))\n",
    "print(td.resolution, type(td.resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(td)\n",
    "print(td.days,td.seconds,td.microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(td.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(td.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(57*24*60*60+5*60*60+8*60+28+52522/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDt1.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = datetime.datetime.strptime('2022-01-04','%Y-%m-%d')\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.hour, tmp.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current time\n",
    "print(datetime.datetime.now())\n",
    "#print(datetime.date.now())\n",
    "#print(datetime.time.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.time(), type(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.fromtimestamp(time.time()))\n",
    "print(datetime.date.fromtimestamp(time.time()))\n",
    "#print(datetime.time.fromtimestamp(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "iters = 1000\n",
    "\n",
    "#start = datetime.datetime.now()\n",
    "start = time.time()\n",
    "for i in range(iters):\n",
    "    squaredIntLC = [x**2 for x in range(n)]\n",
    "end = time.time()\n",
    "#end = datetime.datetime.now()\n",
    "#print((end-start).total_seconds())\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squaredIntFL = []\n",
    "\n",
    "#start = datetime.datetime.now()\n",
    "start = time.time()\n",
    "for i in range(iters):\n",
    "    for x in range(n):\n",
    "        squaredIntFL.append(n**2)\n",
    "end = time.time()\n",
    "#end = datetime.datetime.now()\n",
    "#print((end-start).total_seconds())\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at Python profiling if more functionality is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.datetime64(\"2022-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandDate():\n",
    "    year = np.random.randint(1970,2023)\n",
    "    month = np.random.randint(1,13)\n",
    "    day = np.random.randint(1,29) # to play it safe an easy\n",
    "    hour = np.random.randint(0,24)\n",
    "    minute = np.random.randint(0,60)\n",
    "    second  = np.random.randint(0,60)  \n",
    "    microsecond = np.random.randint(0,1000000)\n",
    "    \n",
    "    return datetime.datetime(year,month,day,hour,minute,second,microsecond)\n",
    "\n",
    "dates = [getRandDate() for i in range(10)]\n",
    "datesString = [date.strftime('%Y-%m-%d %H:%M:%S.%f') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dates,dtype=np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dates,dtype='datetime64[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(datesString,dtype=np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.strptime(datesString[2],'%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(datesString,dtype=np.datetime64)-np.array(dates,dtype='datetime64[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(datesString,dtype='datetime64[us]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is very good at representing time series as well. The way to do it is to use the index as the time stamps of the data. The data type for this Pandas's own `datetime` (or `Timestamp`) data structure. Pandas can directly parse the datetime information given as strings (there are multiple formats). We need to specify the date columns when reading the files. For example we use the `parse_dates` argument of the `read_csv` file.\n",
    "\n",
    "Let's see an example with the following file:  \n",
    "`date, conc`  \n",
    "`2014-04-01, 0.19`  \n",
    "`2014-04-02, 0.23`  \n",
    "`2014-04-03, 0.32`  \n",
    "`2014-04-04, 0.29`  \n",
    "`2014-04-05, 0.32`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('timeseries1.dat', parse_dates=[0], skipinitialspace=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['date'].values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('timeseries1.dat', skipinitialspace=True)\n",
    "tmp['date'].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('datetime of row 0:', data.iloc[0, 0])\n",
    "print('year  of row 0:', data.iloc[0, 0].year)\n",
    "print('month of row 0:', data.iloc[0, 0].month)\n",
    "print('day   of row 0:', data.iloc[0, 0].day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolution of the previous data was a single day. We can also represent hours, minutes and seconds as well, along with the time.\n",
    "\n",
    "`date, conc`   \n",
    "`2014-04-01 12:00:00, 0.19`   \n",
    "`2014-04-01 13:00:00, 0.20`  \n",
    "`2014-04-01 14:00:00, 0.23`  \n",
    "`2014-04-01 15:00:00, 0.21` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('timeseries2.dat', parse_dates=[0], skipinitialspace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0th row hour:', data.iloc[0, 0].hour)\n",
    "print('0th row minutes:', data.iloc[0, 0].minute)\n",
    "print('0th row seconds:', data.iloc[0, 0].second)\n",
    "print('0th row entire time:', data.iloc[0, 0].time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing with Time\n",
    "We can use the `datetime` objects to access and slice DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('timeseries1.dat', parse_dates=[0], index_col=0)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('April 1:', data.loc['2014-04-01'])\n",
    "print('April 2:', data.loc['2014-04-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Between April 2 and April 4:\\n', data.loc['2014-04-02':'2014-04-04'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Older than April 3:\\n', data.loc[data.index<'2014-04-03']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.index<='2014-04-03') & (data.index>'2014-04-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('timeseries2.dat', parse_dates=[0], index_col=0)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['2014-04-01 12:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data.index[1]-data.index[0]\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('timeseries1s.dat') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('timeseries1s.dat', parse_dates=[0], index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.index<='2014-04-03') & (data.index>'2014-04-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Between April 2 and April 4:\\n', data.loc['2014-04-02':'2014-04-04'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
